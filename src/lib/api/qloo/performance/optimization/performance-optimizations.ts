/**
 * Optimisations de performance avanc√©es pour l'API Qloo
 * Bas√©es sur l'analyse des logs de performance
 */

import { optimizedCache } from '../cache/optimized-cache';
import { requestBatcher, prioritizer } from '../requests/request-batcher';

interface PerformanceConfig {
    maxConcurrentRequests: number;
    requestTimeout: number;
    cacheStrategy: 'aggressive' | 'balanced' | 'conservative';
    batchingEnabled: boolean;
    priorityEnabled: boolean;
    monitoringEnabled: boolean;
    fallbackEnabled: boolean;
    retryAttempts: number;
    retryDelay: number;
}

interface PerformanceMetrics {
    totalRequests: number;
    successfulRequests: number;
    failedRequests: number;
    averageResponseTime: number;
    cacheHitRate: number;
    batchEfficiency: number;
    errorRate: number;
    lastUpdated: number;
}

interface OptimizationResult {
    success: boolean;
    data?: any;
    fromCache: boolean;
    responseTime: number;
    batchSize?: number;
    priority?: number;
    errors?: string[];
}

export class PerformanceOptimizer {
    private config: PerformanceConfig;
    private metrics: PerformanceMetrics;
    private requestQueue: Map<string, Promise<any>> = new Map();
    private performanceHistory: Array<{ timestamp: number; responseTime: number; success: boolean }> = [];

    constructor(config: Partial<PerformanceConfig> = {}) {
        this.config = {
            maxConcurrentRequests: 5,
            requestTimeout: 8000, // 8 secondes
            cacheStrategy: 'balanced',
            batchingEnabled: true,
            priorityEnabled: true,
            monitoringEnabled: true,
            fallbackEnabled: true,
            retryAttempts: 2,
            retryDelay: 1000,
            ...config
        };

        this.metrics = {
            totalRequests: 0,
            successfulRequests: 0,
            failedRequests: 0,
            averageResponseTime: 0,
            cacheHitRate: 0,
            batchEfficiency: 0,
            errorRate: 0,
            lastUpdated: Date.now()
        };
    }

    /**
     * Optimise une requ√™te avec toutes les strat√©gies disponibles
     */
    async optimizeRequest<T>(
        entityType: string,
        params: any,
        requestFn: (params: any) => Promise<T>,
        options: {
            priority?: number;
            skipCache?: boolean;
            timeout?: number;
            fallbackData?: T;
        } = {}
    ): Promise<OptimizationResult> {
        const startTime = Date.now();
        const requestId = this.generateRequestId(entityType, params);

        try {
            this.metrics.totalRequests++;

            // 1. V√©rifier le cache d'abord
            if (!options.skipCache) {
                const cacheKey = optimizedCache.generateKey({ entityType, ...params });
                const cachedData = optimizedCache.get<T>(cacheKey);

                if (cachedData) {
                    const responseTime = Date.now() - startTime;
                    this.updateMetrics(responseTime, true, true);

                    return {
                        success: true,
                        data: cachedData,
                        fromCache: true,
                        responseTime
                    };
                }
            }

            // 2. D√©duplication des requ√™tes identiques
            if (this.requestQueue.has(requestId)) {
                console.log(`üîÑ Requ√™te d√©dupliqu√©e: ${entityType}`);
                const data = await this.requestQueue.get(requestId);
                const responseTime = Date.now() - startTime;

                return {
                    success: true,
                    data,
                    fromCache: false,
                    responseTime
                };
            }

            // 3. Traitement optimis√© avec batching et priorit√©s
            const optimizedPromise = this.executeOptimizedRequest(
                entityType,
                params,
                requestFn,
                options
            );

            this.requestQueue.set(requestId, optimizedPromise);

            const result = await optimizedPromise;
            this.requestQueue.delete(requestId);

            const responseTime = Date.now() - startTime;
            this.updateMetrics(responseTime, true, false);

            // 4. Mise en cache du r√©sultat
            if (result && !options.skipCache) {
                const cacheKey = optimizedCache.generateKey({ entityType, ...params });
                const ttl = this.calculateOptimalTTL(entityType, result);
                optimizedCache.set(cacheKey, result, ttl);
            }

            return {
                success: true,
                data: result,
                fromCache: false,
                responseTime,
                priority: options.priority
            };

        } catch (error) {
            const responseTime = Date.now() - startTime;
            this.updateMetrics(responseTime, false, false);

            console.error(`‚ùå Erreur optimisation ${entityType}:`, error);

            // 5. Strat√©gie de fallback
            if (this.config.fallbackEnabled && options.fallbackData) {
                return {
                    success: true,
                    data: options.fallbackData,
                    fromCache: false,
                    responseTime,
                    errors: [error instanceof Error ? error.message : 'Unknown error']
                };
            }

            return {
                success: false,
                fromCache: false,
                responseTime,
                errors: [error instanceof Error ? error.message : 'Unknown error']
            };
        }
    }

    /**
     * Ex√©cute une requ√™te avec toutes les optimisations
     */
    private async executeOptimizedRequest<T>(
        entityType: string,
        params: any,
        requestFn: (params: any) => Promise<T>,
        options: any
    ): Promise<T> {
        const timeout = options.timeout || this.config.requestTimeout;

        // Utiliser le batcher si activ√©
        if (this.config.batchingEnabled) {
            const priority = this.config.priorityEnabled
                ? (options.priority || prioritizer.getPriority(entityType, params))
                : 1;

            return await requestBatcher.batchRequest(
                entityType,
                params,
                priority,
                (batchParams) => this.executeWithTimeout(requestFn, batchParams, timeout)
            );
        }

        // Ex√©cution directe avec timeout
        return await this.executeWithTimeout(requestFn, params, timeout);
    }

    /**
     * Ex√©cute une requ√™te avec timeout et retry
     */
    private async executeWithTimeout<T>(
        requestFn: (params: any) => Promise<T>,
        params: any,
        timeout: number
    ): Promise<T> {
        let lastError: Error | null = null;

        for (let attempt = 0; attempt <= this.config.retryAttempts; attempt++) {
            try {
                const timeoutPromise = new Promise<never>((_, reject) => {
                    setTimeout(() => reject(new Error('Request timeout')), timeout);
                });

                const result = await Promise.race([
                    requestFn(params),
                    timeoutPromise
                ]);

                return result;

            } catch (error) {
                lastError = error instanceof Error ? error : new Error('Unknown error');

                if (attempt < this.config.retryAttempts) {
                    console.log(`üîÑ Retry ${attempt + 1}/${this.config.retryAttempts} apr√®s ${this.config.retryDelay}ms`);
                    await this.sleep(this.config.retryDelay * (attempt + 1)); // Backoff exponentiel
                }
            }
        }

        throw lastError;
    }

    /**
     * Calcule le TTL optimal bas√© sur le type d'entit√© et la qualit√© des donn√©es
     */
    private calculateOptimalTTL(entityType: string, data: any): number {
        const baseStrategy = this.config.cacheStrategy;
        let baseTTL: number;

        switch (baseStrategy) {
            case 'aggressive':
                baseTTL = 2 * 60 * 60 * 1000; // 2 heures
                break;
            case 'conservative':
                baseTTL = 30 * 60 * 1000; // 30 minutes
                break;
            default: // balanced
                baseTTL = 60 * 60 * 1000; // 1 heure
        }

        // Ajustements bas√©s sur le type d'entit√©
        const entityMultipliers: Record<string, number> = {
            music: 1.5,      // Pr√©f√©rences musicales stables
            movie: 1.3,      // Pr√©f√©rences cin√©ma assez stables
            book: 1.8,       // Pr√©f√©rences livres tr√®s stables
            brand: 1.2,      // Marques changent mod√©r√©ment
            tv: 1.4,         // Pr√©f√©rences TV stables
            fashion: 0.6,    // Mode change rapidement
            beauty: 0.7,     // Beaut√© change assez vite
            food: 1.0,       // Nourriture mod√©r√©ment stable
            travel: 1.6,     // Voyage assez stable
            restaurant: 0.9, // Restaurants changent
            person: 1.4,     // Personnes assez stables
            socialMedia: 0.5 // R√©seaux sociaux tr√®s volatils
        };

        const multiplier = entityMultipliers[entityType] || 1.0;

        // Ajustement bas√© sur la qualit√© des donn√©es
        let qualityMultiplier = 1.0;
        if (Array.isArray(data) && data.length > 0) {
            qualityMultiplier = Math.min(1.5, 1 + (data.length / 20));
        }

        return Math.round(baseTTL * multiplier * qualityMultiplier);
    }

    /**
     * Met √† jour les m√©triques de performance
     */
    private updateMetrics(responseTime: number, success: boolean, fromCache: boolean): void {
        if (success) {
            this.metrics.successfulRequests++;
        } else {
            this.metrics.failedRequests++;
        }

        // Mise √† jour du temps de r√©ponse moyen
        const totalSuccessful = this.metrics.successfulRequests;
        this.metrics.averageResponseTime =
            (this.metrics.averageResponseTime * (totalSuccessful - 1) + responseTime) / totalSuccessful;

        // Mise √† jour du taux d'erreur
        this.metrics.errorRate = this.metrics.failedRequests / this.metrics.totalRequests;

        // Mise √† jour des statistiques de cache
        const cacheStats = optimizedCache.getStats();
        this.metrics.cacheHitRate = cacheStats.hitRate;

        // Historique de performance
        this.performanceHistory.push({
            timestamp: Date.now(),
            responseTime,
            success
        });

        // Garder seulement les 1000 derni√®res entr√©es
        if (this.performanceHistory.length > 1000) {
            this.performanceHistory = this.performanceHistory.slice(-1000);
        }

        this.metrics.lastUpdated = Date.now();

        if (this.config.monitoringEnabled) {
            this.logPerformanceMetrics();
        }
    }

    /**
     * G√©n√®re un ID unique pour une requ√™te
     */
    private generateRequestId(entityType: string, params: any): string {
        const key = JSON.stringify({ entityType, ...params });
        return Buffer.from(key).toString('base64').slice(0, 16);
    }

    /**
     * Log des m√©triques de performance
     */
    private logPerformanceMetrics(): void {
        if (this.metrics.totalRequests % 10 === 0) { // Log tous les 10 requ√™tes
            console.log(`üìä Performance Metrics:
        Total: ${this.metrics.totalRequests}
        Success Rate: ${((this.metrics.successfulRequests / this.metrics.totalRequests) * 100).toFixed(1)}%
        Avg Response: ${this.metrics.averageResponseTime.toFixed(0)}ms
        Cache Hit Rate: ${(this.metrics.cacheHitRate * 100).toFixed(1)}%
        Error Rate: ${(this.metrics.errorRate * 100).toFixed(1)}%`);
        }
    }

    /**
     * Obtient les m√©triques actuelles
     */
    getMetrics(): PerformanceMetrics {
        return { ...this.metrics };
    }

    /**
     * Obtient l'historique de performance
     */
    getPerformanceHistory(): Array<{ timestamp: number; responseTime: number; success: boolean }> {
        return [...this.performanceHistory];
    }

    /**
     * R√©initialise les m√©triques
     */
    resetMetrics(): void {
        this.metrics = {
            totalRequests: 0,
            successfulRequests: 0,
            failedRequests: 0,
            averageResponseTime: 0,
            cacheHitRate: 0,
            batchEfficiency: 0,
            errorRate: 0,
            lastUpdated: Date.now()
        };
        this.performanceHistory = [];
    }

    /**
     * Met √† jour la configuration
     */
    updateConfig(newConfig: Partial<PerformanceConfig>): void {
        this.config = { ...this.config, ...newConfig };
        console.log(`‚öôÔ∏è Configuration mise √† jour:`, newConfig);
    }

    /**
     * Nettoie les ressources
     */
    cleanup(): void {
        this.requestQueue.clear();
        this.performanceHistory = [];
    }

    private sleep(ms: number): Promise<void> {
        return new Promise(resolve => setTimeout(resolve, ms));
    }
}

// Instance singleton avec configuration optimis√©e
export const performanceOptimizer = new PerformanceOptimizer({
    maxConcurrentRequests: 5,
    requestTimeout: 8000,
    cacheStrategy: 'balanced',
    batchingEnabled: true,
    priorityEnabled: true,
    monitoringEnabled: true,
    fallbackEnabled: true,
    retryAttempts: 2,
    retryDelay: 1000
});

// Fonctions utilitaires pour l'optimisation
export const optimizationUtils = {
    /**
     * Pr√©chauffe le cache avec des requ√™tes communes
     */
    async warmupCache(commonRequests: Array<{ entityType: string; params: any }>): Promise<void> {
        console.log(`üî• Pr√©chauffage du cache avec ${commonRequests.length} requ√™tes`);

        const warmupData = commonRequests.map(req => ({
            key: optimizedCache.generateKey({ entityType: req.entityType, ...req.params }),
            data: null // Sera rempli par les vraies requ√™tes
        }));

        await optimizedCache.warmCache(warmupData);
    },

    /**
     * Analyse les performances et sugg√®re des optimisations
     */
    analyzePerformance(): {
        recommendations: string[];
        criticalIssues: string[];
        score: number;
    } {
        const metrics = performanceOptimizer.getMetrics();
        const recommendations: string[] = [];
        const criticalIssues: string[] = [];
        let score = 100;

        // Analyse du taux de cache
        if (metrics.cacheHitRate < 0.3) {
            criticalIssues.push('Taux de cache tr√®s faible (<30%)');
            recommendations.push('Augmenter la dur√©e de vie du cache');
            recommendations.push('Am√©liorer la normalisation des cl√©s de cache');
            score -= 20;
        } else if (metrics.cacheHitRate < 0.5) {
            recommendations.push('Optimiser la strat√©gie de cache');
            score -= 10;
        }

        // Analyse du temps de r√©ponse
        if (metrics.averageResponseTime > 5000) {
            criticalIssues.push('Temps de r√©ponse tr√®s √©lev√© (>5s)');
            recommendations.push('R√©duire le timeout des requ√™tes');
            recommendations.push('Activer le batching agressif');
            score -= 25;
        } else if (metrics.averageResponseTime > 3000) {
            recommendations.push('Optimiser les requ√™tes lentes');
            score -= 15;
        }

        // Analyse du taux d'erreur
        if (metrics.errorRate > 0.1) {
            criticalIssues.push('Taux d\'erreur √©lev√© (>10%)');
            recommendations.push('Am√©liorer la gestion des erreurs');
            recommendations.push('Activer les fallbacks');
            score -= 20;
        } else if (metrics.errorRate > 0.05) {
            recommendations.push('Surveiller les erreurs');
            score -= 10;
        }

        return {
            recommendations,
            criticalIssues,
            score: Math.max(0, score)
        };
    },

    /**
     * G√©n√®re un rapport de performance d√©taill√©
     */
    generatePerformanceReport(): {
        summary: any;
        metrics: PerformanceMetrics;
        cacheStats: any;
        analysis: any;
        timestamp: number;
    } {
        const metrics = performanceOptimizer.getMetrics();
        const cacheStats = optimizedCache.getStats();
        const analysis = this.analyzePerformance();
        const history = performanceOptimizer.getPerformanceHistory();

        const recentHistory = history.slice(-100); // 100 derni√®res requ√™tes
        const avgRecentResponseTime = recentHistory.length > 0
            ? recentHistory.reduce((sum, h) => sum + h.responseTime, 0) / recentHistory.length
            : 0;

        return {
            summary: {
                totalRequests: metrics.totalRequests,
                successRate: metrics.totalRequests > 0
                    ? (metrics.successfulRequests / metrics.totalRequests * 100).toFixed(1) + '%'
                    : '0%',
                averageResponseTime: metrics.averageResponseTime.toFixed(0) + 'ms',
                recentAverageResponseTime: avgRecentResponseTime.toFixed(0) + 'ms',
                cacheHitRate: (metrics.cacheHitRate * 100).toFixed(1) + '%',
                performanceScore: analysis.score + '/100'
            },
            metrics,
            cacheStats,
            analysis,
            timestamp: Date.now()
        };
    }
};